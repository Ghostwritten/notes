上一节我们谈论到了Nginx的事件分发机制,在这个循环流程中,Nginx怎样能够快速的从操作系统的KERNEL中获取到等待处理的事件;这么一个简单的步骤,其实经历了很长时间才得以想出办法解决;

　　比如,到现在Nginx主要在使用`epool`这样一个网络事件收集器的模型:

　　现在我们简单来回顾下epool主要有些什么样的特点?

　　常见时间模型的性能如下:
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5b2ef4a1bd48e27f1f29e411b8f188a5.png)
随着横轴并发连接数的增加,纵轴消耗时间的展示;epool的消耗时间与并发连接基本上是无关的,所以它非常适合使用大并发连接的处理;

为什么会这样?
我们来看它的场景:

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/ddb18123d3a55d5e09e00460935061e7.png)
比如说我们nginx现在要处理 100万的连接,那么从我们之前所谈到的事件分发图中可以看到,我们每两次做等待新的连接中,时间可能会非常的短.在短短的几百毫秒这样的一个量级的时间中,所能收到的报文数量是有限的,而这些有限的事件对应的连接也是有限的;也就是每次我处理事件时虽然我总共有100万的并发连接;但我可能只接收到几百个活跃的连接,我只需要处理几百个活跃的请求,**而select和poll它们的实现是有问题的,因为每一次我去取操作系统的事件的时候,我都需要把这100万个连接扔给操作系统;让它判断哪些连接上面有事件进来了,所以可以看到这里操作系统做了大量的无用功,它扫描了大量的不活跃的连接,那么epoll尼,就使用了这样一个特性,因为每次处理活跃连接的占比其实非常的小,它怎么实现的尼?其实非常简单,因为它维护了一个数据结构叫eventpoll,这里它通过两个数据结构把两个数据给分开了,也就说我们Nginx每次取活跃连接的时候,我们只需要遍历一个链表,这个链表里仅仅只有活跃的连接,这样我们的速度和效率就会很高**,那么我们还会经常做的操作是什么尼?比如说:**nginx收到80端口建立连接的请求,建立成功以后尼,我要添加一个读事件,这个读事件是我要用来读取HTTP消息的,那这个时候尼,我可能会添加一个新的事件或者写事件添加进来,这个时候添加的它只会放到红黑树中,二叉树可以保证我的插入效率是log(n),如果现在我不想再处理读事件或者写事件了,只需要从二叉树中移除一个节点就行了,同样效率是`log(n)`**;

　　那么什么时候这个链表会有所增减?

　　当我们读取一个事件的时候,链表中就没了,当操作系统中接收到网卡中一个报文的时候,那么这个链表就会增加一个新的元素,所以我们在使用epoll的时候,它的操作:添加,修改,删除的时候是非常快的,是log(n)的复杂度的;而我们去获取句柄的时候只是去遍历rdllink 准备好的链接:从内核态到用户态;所以说它的效率是非常高的;

　　以上简单介绍了epoll的使用方法,它对于我们理解nginx的事件驱动模型是有帮助的;
